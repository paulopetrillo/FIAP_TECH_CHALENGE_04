# app_streamlit_bvsp_svm.py
import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
from datetime import datetime

from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

import altair as alt


# =========================
# Config
# =========================
st.set_page_config(page_title="PAINEL BVSP + SVM", layout="wide")
st.title("ðŸ“ˆ Painel BVSP (IBOV) + PrevisÃ£o com SVM")
st.caption("Deploy + Monitoramento do modelo (FIAP - Tech Challenge Fase 4).")

with st.expander("ðŸ“Œ InstruÃ§Ãµes de Uso"):
    st.write(
        """
**O que este app faz (clarinho):**
- **GrÃ¡fico de preÃ§os**: vem do **Yahoo Finance (ao vivo)** para o ticker que vocÃª digitar.
- **PrevisÃ£o e mÃ©tricas do modelo SVM**: usam o **dataset tratado do notebook** (`dados_tratados_data_correta.csv`).
  - Isso Ã© intencional para **reproduzir a lÃ³gica/mÃ©tricas do notebook** (ex.: acurÃ¡cia 0,867).
- Para nÃ£o confundir:
  - **Ticker do Yahoo** = apenas indicadores e grÃ¡fico.
  - **Modelo SVM** = previsÃ£o calculada no dataset tratado (nÃ£o depende do ticker).
"""
    )


# =========================
# Defaults
# =========================
DEFAULT_DATA_URL = (
    "https://raw.githubusercontent.com/paulopetrillo/"
    "FIAP_TECH_CHALENGE_04/main/dados_tratados_data_correta.csv"
)


# =========================
# Helpers / Loaders
# =========================
@st.cache_resource
def load_model_and_features():
    """Espera joblib como dict: {'model': ..., 'feature_cols': [...], 'threshold': ... (opcional)}"""
    path = Path(__file__).parent / "models" / "svm_bvsp.joblib"
    artifact = joblib.load(path)

    if not isinstance(artifact, dict):
        raise TypeError("O arquivo joblib nÃ£o Ã© um dict. Salve como {'model':..., 'feature_cols':...}.")

    if "model" not in artifact:
        raise KeyError("NÃ£o achei a chave 'model' dentro do artifact (.joblib).")

    if "feature_cols" not in artifact:
        raise KeyError("NÃ£o achei a chave 'feature_cols' dentro do artifact (.joblib).")

    model = artifact["model"]
    features = list(artifact["feature_cols"])
    threshold = float(artifact.get("threshold", 0.5))  # opcional

    return model, features, threshold


@st.cache_data(ttl=3600)
def load_dataset(local_first: bool, data_url: str) -> pd.DataFrame:
    """Carrega dataset tratado: tenta local (raiz ou data/), senÃ£o usa URL raw."""
    if local_first:
        root = Path(__file__).parent / "dados_tratados_data_correta.csv"
        data_dir = Path(__file__).parent / "data" / "dados_tratados_data_correta.csv"

        if root.exists():
            return pd.read_csv(root)
        if data_dir.exists():
            return pd.read_csv(data_dir)

    return pd.read_csv(data_url)


@st.cache_data(ttl=3600)
def fetch_market_history(ticker_symbol: str, years: int) -> pd.DataFrame:
    """HistÃ³rico do Yahoo atÃ© o Ãºltimo pregÃ£o disponÃ­vel."""
    emp = yf.Ticker(ticker_symbol)
    hist = emp.history(period=f"{years}y")
    return hist


def ensure_datetime_index(df: pd.DataFrame) -> pd.DataFrame:
    """Tenta colocar Data/Date como Ã­ndice datetime (se existir)."""
    df = df.copy()
    for col in ["Date", "date", "Data", "DATA"]:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors="coerce")
            df = df.dropna(subset=[col]).sort_values(col).set_index(col)
            return df
    return df


def align_X_to_model(X: pd.DataFrame, model) -> pd.DataFrame:
    """NumÃ©rico, ordem de colunas do treino (se existir), remove NaNs."""
    X = X.copy().apply(pd.to_numeric, errors="coerce")

    # Se Pipeline, tenta usar feature_names_in_ (normalmente do scaler)
    if isinstance(model, Pipeline):
        for step_name, step in model.named_steps.items():
            if hasattr(step, "feature_names_in_"):
                expected = list(step.feature_names_in_)
                missing = [c for c in expected if c not in X.columns]
                if missing:
                    raise ValueError(f"Faltam colunas esperadas no pipeline ({step_name}): {missing}")
                X = X.reindex(columns=expected)
                break

    X = X.loc[X.notna().all(axis=1)]
    return X


def append_log(row: dict) -> None:
    logs_dir = Path(__file__).parent / "logs"
    logs_dir.mkdir(exist_ok=True)
    log_path = logs_dir / "usage_log.csv"

    df_row = pd.DataFrame([row])
    if log_path.exists():
        df_row.to_csv(log_path, mode="a", header=False, index=False, encoding="utf-8")
    else:
        df_row.to_csv(log_path, mode="w", header=True, index=False, encoding="utf-8")


def sigmoid(x: float) -> float:
    return 1.0 / (1.0 + np.exp(-x))


def fmt_brl(x: float) -> str:
    # 12345.67 -> "R$ 12.345,67"
    s = f"{x:,.2f}"
    s = s.replace(",", "X").replace(".", ",").replace("X", ".")
    return f"R$ {s}"


# =========================
# Sidebar (controles)
# =========================
st.sidebar.header("âš™ï¸ ConfiguraÃ§Ãµes")

ticker = st.sidebar.text_input("Ticker (use ^BVSP para Ã­ndice)", "^BVSP").strip().upper()
ticker_symbol = f"{ticker}.SA" if ticker != "^BVSP" else "^BVSP"

years = st.sidebar.slider("HistÃ³rico (anos) â€” Yahoo", 1, 15, 10)
n_test = st.sidebar.slider("Janela (Ãºltimos pregÃµes) â€” teste/mÃ©tricas (dataset tratado)", 5, 252, 30)

root_path = Path(__file__).parent / "dados_tratados_data_correta.csv"
data_path = Path(__file__).parent / "data" / "dados_tratados_data_correta.csv"

local_data_first = st.sidebar.checkbox(
    "Usar dataset local (raiz ou data/)",
    value=True
)

data_url = st.sidebar.text_input("Fallback URL (raw) do dataset tratado", DEFAULT_DATA_URL)

enable_logging = st.sidebar.checkbox("Salvar log de uso (CSV)", value=True)
show_monitoring = st.sidebar.checkbox("Mostrar painel de monitoramento", value=True)

show_last_features = st.checkbox("Mostrar Ãºltimas features", value=True)
show_yahoo_indicators = st.checkbox("Mostrar indicadores do Ãºltimo dia (Yahoo)", value=True)

# BotÃ£o de recarregar (limpa cache)
if st.sidebar.button("ðŸ”„ Recarregar dados (limpar cache)"):
    st.cache_data.clear()
    st.cache_resource.clear()
    st.rerun()

# Debug (opcional, mas ajuda muito)
st.sidebar.caption(f"Local (raiz) existe? {root_path.exists()}")
st.sidebar.caption(f"Local (data/) existe? {data_path.exists()}")
st.sidebar.markdown(
    f"**Fonte selecionada:** {'LOCAL' if (local_data_first and (root_path.exists() or data_path.exists())) else 'URL'}"
)

# =========================
# Carregar modelo
# =========================
try:
    model, FEATURES, threshold = load_model_and_features()
    st.success(f"Modelo carregado: {type(model).__name__} | #features: {len(FEATURES)}")
except Exception as e:
    st.error("Falha ao carregar o modelo (models/svm_bvsp.joblib).")
    st.exception(e)
    st.stop()


# =========================
# SeÃ§Ã£o A â€” Mercado (Yahoo)
# =========================
st.subheader("ðŸ“Š Mercado (Yahoo Finance) â€” **usa o ticker escolhido**")

with st.spinner("Baixando histÃ³rico do Yahoo Finance..."):
    hist = fetch_market_history(ticker_symbol, years)

if hist.empty:
    st.warning("Sem histÃ³rico retornado pelo Yahoo Finance para esse ticker.")
else:
    last_dt = hist.index.max()
    st.caption(f"Ãšltima data disponÃ­vel no Yahoo (histÃ³rico): **{last_dt.date()}**")

    colA, colB, colC = st.columns(3)
    colA.metric("Ãšltimo Close (Yahoo)", fmt_brl(float(hist["Close"].iloc[-1])))
    colB.metric("MÃ¡ximo (perÃ­odo)", fmt_brl(float(hist["Close"].max())))
    colC.metric("MÃ­nimo (perÃ­odo)", fmt_brl(float(hist["Close"].min())))

    price_df = hist.reset_index()[["Date", "Close"]].dropna()
    chart = (
        alt.Chart(price_df)
        .mark_line()
        .encode(
            x=alt.X("Date:T", title="Data"),
            y=alt.Y("Close:Q", title=f"Fechamento â€” {ticker_symbol} (Yahoo)"),
            tooltip=["Date:T", "Close:Q"],
        )
        .interactive()
    )
    st.altair_chart(chart, use_container_width=True)

# pegar indicadores do Yahoo (Ãºltimo e anterior) para exibir
yahoo_last_close = None
yahoo_prev_close = None
yahoo_pct = None

if not hist.empty and "Close" in hist.columns and len(hist) >= 2:
    yahoo_last_close = float(hist["Close"].iloc[-1])
    yahoo_prev_close = float(hist["Close"].iloc[-2])
    yahoo_pct = (yahoo_last_close / yahoo_prev_close - 1.0) * 100.0

st.divider()


# =========================
# SeÃ§Ã£o B â€” Modelo (dataset tratado)
# =========================
st.warning(
    "âš ï¸ **Esta seÃ§Ã£o NÃƒO usa o ticker para prever.** "
    "A previsÃ£o/mÃ©tricas vÃªm do **dataset tratado do notebook** para reproduzir seu experimento."
)

with st.expander("ðŸ“„ Ver preview do dataset tratado"):
    try:
        df_raw_preview = load_dataset(local_data_first, data_url)
        st.dataframe(df_raw_preview.tail(20), use_container_width=True)
    except Exception as e:
        st.error("Falha ao carregar preview do dataset tratado.")
        st.exception(e)

st.subheader("ðŸ§  PrevisÃ£o (Ãºltimos N registros do dataset tratado)")

# carregar dataset tratado (de verdade)
try:
    used_local = local_data_first and (root_path.exists() or data_path.exists())
    df_raw = load_dataset(local_data_first, data_url)
    df = ensure_datetime_index(df_raw)
except Exception as e:
    st.error("Falha ao carregar o dataset tratado.")
    st.exception(e)
    st.stop()

# validaÃ§Ãµes
if "Target" not in df_raw.columns and "Target" not in df.columns:
    st.error("O dataset precisa ter a coluna **Target** (como no notebook).")
    st.stop()

# y
y_all = (df["Target"] if "Target" in df.columns else df_raw["Target"]).astype(int).copy()

# X
missing_feats = [c for c in FEATURES if c not in df_raw.columns and c not in df.columns]
if missing_feats:
    st.error("Faltam features no dataset tratado (nÃ£o bate com o modelo).")
    st.write(missing_feats)
    st.stop()

base_df = df if all(c in df.columns for c in FEATURES) else df_raw
X_all = base_df[FEATURES].copy()

try:
    X_all = align_X_to_model(X_all, model)
    y_all = y_all.loc[X_all.index]  # alinha apÃ³s dropna
except Exception as e:
    st.error("Falha ao alinhar X para o modelo (ordem/colunas/nÃºmeros).")
    st.exception(e)
    st.stop()

# UI: botÃ£o
btn = st.button("Gerar previsÃ£o", type="primary")

if btn:
    X_test = X_all.tail(int(n_test))
    y_test = y_all.tail(int(n_test))

    if X_test.empty:
        st.warning("Sem dados suficientes para prever (X_test vazio).")
        st.stop()

    # Prever
    y_pred = model.predict(X_test)

    # Score (0-1) opcional: decision_function -> sigmoid
    score01 = None
    if hasattr(model, "decision_function"):
        try:
            dec = model.decision_function(X_test.iloc[[-1]])
            score01 = float(sigmoid(float(np.ravel(dec)[0])))
        except Exception:
            score01 = None

    # resultado
    last_pred = int(y_pred[-1])

    # Data de referÃªncia: Ãºltimo index do dataset tratado
    ref_date = X_test.index[-1] if hasattr(X_test, "index") else None

    # texto de confianÃ§a (apenas visual)
    conf_txt = ""
    if score01 is not None:
        if score01 >= 0.65 or score01 <= 0.35:
            conf_txt = "ConfianÃ§a alta"
        elif score01 >= 0.55 or score01 <= 0.45:
            conf_txt = "ConfianÃ§a mÃ©dia"
        else:
            conf_txt = "ConfianÃ§a baixa"

    st.markdown("## Resultado")
    st.success("TendÃªncia de **ALTA (classe 1)**." if last_pred == 1 else "TendÃªncia de **BAIXA (classe 0)**.")

    # ---- ORIGEM (para nÃ£o confundir) ----
    st.markdown("#### Origem dos dados exibidos")
    o1, o2 = st.columns(2)

    with o1:
        st.info(
            "ðŸ§  **PrevisÃ£o do MODELO (SVM)**\n\n"
            "- Fonte: **dataset tratado do notebook**\n"
            "- **NÃ£o depende do ticker** digitado\n"
            f"- Janela usada: Ãºltimos **{int(n_test)}** registros do dataset"
        )

    with o2:
        st.info(
            "ðŸ“Š **Indicadores do YAHOO (informativo)**\n\n"
            f"- Ticker escolhido: **{ticker_symbol}**\n"
            "- Fonte: **Yahoo Finance**\n"
            "- **NÃ£o entra no cÃ¡lculo do SVM nesta versÃ£o**"
        )

    # ---- MÃ©tricas topo (layout igual ao seu print) ----
    m1, m2, m3 = st.columns(3)

    # Data de referÃªncia: do dataset tratado (o que o modelo realmente usou)
    if isinstance(ref_date, (pd.Timestamp, datetime)):
        m1.metric("Data de referÃªncia (dataset tratado)", ref_date.date().isoformat())
    else:
        m1.metric("Data de referÃªncia (dataset tratado)", "â€”")

    # Ãšltimo fechamento: do Yahoo do ticker (informativo)
    if yahoo_last_close is not None:
        m2.metric(f"Ãšltimo fechamento do ticker no Yahoo ({ticker_symbol})", fmt_brl(yahoo_last_close))
    else:
        m2.metric(f"Ãšltimo fechamento do ticker no Yahoo ({ticker_symbol})", "â€”")

    # Score do modelo
    if score01 is not None:
        m3.metric("Score do MODELO (0â€“1)", f"{score01:.3f}")
    else:
        m3.metric("Score do MODELO (0â€“1)", "â€”")

    st.caption(
        "Score do MODELO Ã© uma transformaÃ§Ã£o logÃ­stica do `decision_function` "
        "(**nÃ£o Ã© probabilidade real**)."
    )
    if conf_txt:
        st.caption(conf_txt)

    # ---- Ãšltimas features (dataset tratado) ----
    X_last = X_test.tail(1).copy()
    if show_last_features:
        st.markdown("### Ãšltimas features usadas (linha final do dataset tratado)")
        show_df = X_last.copy()
        show_df.insert(0, "Data", [ref_date] if ref_date is not None else ["â€”"])
        st.dataframe(show_df, use_container_width=True)

    # ---- Indicadores Yahoo (informativo) ----
    if show_yahoo_indicators:
        st.markdown(f"### Indicadores do Ãºltimo dia (Yahoo) â€” {ticker_symbol} (informativo)")
        if yahoo_last_close is None or yahoo_prev_close is None:
            st.info("Yahoo nÃ£o retornou dados suficientes para calcular indicadores do dia.")
        else:
            i1, i2, i3 = st.columns(3)
            i1.metric("Close (Ãºltimo)", fmt_brl(yahoo_last_close))
            i2.metric("Close (anterior)", fmt_brl(yahoo_prev_close))
            i3.metric("VariaÃ§Ã£o %", f"{yahoo_pct:+.2f}%")

    # ---- Log de uso ----
    if enable_logging:
        append_log(
            {
                "timestamp": datetime.now().isoformat(timespec="seconds"),
                "ticker_input": ticker,
                "ticker_symbol": ticker_symbol,
                "years_yahoo_chart": int(years),
                "n_test_dataset": int(n_test),
                "last_pred": last_pred,
                "score01": score01 if score01 is not None else "",
                "dataset_source": "local" if used_local else "url",
            }
        )
        st.success("Log salvo em logs/usage_log.csv")

    # ---- Salvar no session_state para painel de monitoramento ----
    st.session_state["y_test"] = y_test
    st.session_state["y_pred"] = y_pred

    # ---- GrÃ¡fico Real x Previsto (dataset tratado) ----
    plot_df = pd.DataFrame(
        {
            "Real": y_test.values.astype(int),
            "Previsto": pd.Series(y_pred, index=y_test.index).astype(int),
        },
        index=y_test.index,
    ).reset_index().rename(columns={"index": "Data"})

    melt = plot_df.melt(id_vars="Data", value_vars=["Real", "Previsto"], var_name="SÃ©rie", value_name="Classe")

    is_dt = np.issubdtype(plot_df["Data"].dtype, np.datetime64)

    chart2 = (
        alt.Chart(melt)
        .mark_line(point=True)
        .encode(
            x=alt.X("Data:T" if is_dt else "Data:O", title="Data (dataset tratado)"),
            y=alt.Y("Classe:Q", title="Classe (0=queda, 1=alta)", scale=alt.Scale(domain=[-0.1, 1.1])),
            color="SÃ©rie:N",
            tooltip=["SÃ©rie:N", "Classe:Q", "Data"],
        )
        .interactive()
    )
    st.altair_chart(chart2, use_container_width=True)

    st.caption("Classe 1 = alta | Classe 0 = queda")


# =========================
# Monitoramento (mÃ©tricas + matriz de confusÃ£o)
# =========================
if show_monitoring:
    st.subheader("ðŸ“Œ Monitoramento do Modelo (mÃ©tricas e performance)")

    if "y_test" not in st.session_state or "y_pred" not in st.session_state:
        st.info("Clique em **Gerar previsÃ£o** para calcular as mÃ©tricas nesta janela.")
    else:
        y_test = st.session_state["y_test"]
        y_pred = st.session_state["y_pred"]

        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)

        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Accuracy", f"{acc:.3f}")
        c2.metric("Precision", f"{prec:.3f}")
        c3.metric("Recall", f"{rec:.3f}")
        c4.metric("F1-score", f"{f1:.3f}")

        cm = confusion_matrix(y_test, y_pred)
        cm_df = pd.DataFrame(cm, index=["Real 0", "Real 1"], columns=["Pred 0", "Pred 1"])

        # prepara dados pro heatmap (Altair)
        cm_plot = cm_df.reset_index().melt(id_vars="index", var_name="Pred", value_name="Count")
        cm_plot = cm_plot.rename(columns={"index": "Real"})

        heatmap = (
            alt.Chart(cm_plot)
            .mark_rect()
            .encode(
                x=alt.X("Pred:N", title="Previsto"),
                y=alt.Y("Real:N", title="Real"),
                tooltip=["Real:N", "Pred:N", "Count:Q"],
            )
        )

        labels = (
            alt.Chart(cm_plot)
            .mark_text()
            .encode(
                x="Pred:N",
                y="Real:N",
                text=alt.Text("Count:Q"),
            )
        )

        st.write("**Matriz de confusÃ£o:**")

        col_left, col_right = st.columns([1, 1.2])  # ajusta o peso se quiser
        with col_left:
            st.dataframe(cm_df, use_container_width=True)

        with col_right:
            st.altair_chart(heatmap + labels, use_container_width=True)



        with st.expander("DiagnÃ³stico (distribuiÃ§Ã£o Real/Previsto)"):
            st.write("DistribuiÃ§Ã£o REAL (Target):")
            st.write(pd.Series(y_test).value_counts().sort_index())
            st.write("DistribuiÃ§Ã£o PREVISTA:")
            st.write(pd.Series(y_pred).value_counts().sort_index())


# =========================
# Requisitos
# =========================
with st.expander("âœ… Como isso atende o Tech Challenge"):
    st.write(
        """
- App em **Streamlit**
- Importa modelo treinado na fase 2 (**joblib**)
- **GrÃ¡fico interativo** (Altair) do Yahoo Finance para o ticker escolhido
- Painel de **mÃ©tricas + matriz de confusÃ£o** (monitoramento)
- **Log de uso** em CSV (logs/usage_log.csv)
"""
    )
